{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "As we have seen cases of different types of data and different ways of processing them to obtain important information out of them, in this section we will talk about one of the most sought upon data in today’s time. \n",
    "Customer Information is the backbone for most of the renowned companies in 21st century. Let’s take example of Google. How do you suppose Google is providing so many services for free? What profit does it make by giving you free services? Well it’s your information that google sells to different companies by analyzing your searches and makes profit through it. The moment you search for a product on google, you will start seeing the product recommendation on every website. \n",
    "This is the most basic usage of text analytics, product recommendation to customers by analyzing their searches. Similarly, many companies analyze the positive or negative reviews given by customers and try to predict the customer behavior. \n",
    "There is a wealth of such unstructured data present such as emails, google searches, online surveys, twitter, online reviews etc. which can be processed using text analysis. Many key information about people, customers can be derived by processing the unstructured text and analyzing. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Natural Language Processing (NLP)\n",
    "\n",
    "\n",
    "NLP is a part of Artificial Intelligence, developed for the machine to understand human language. The ultimate goal of NLP is to read, understand and make valuable conclusion of human language. It is a very tough job to do as human language has a lot of variation in terms of language, pronunciation etc. Although, in recent times there has been a major breakthrough in the field of NLP. \n",
    "\n",
    "Siri and Alexa are one such example of uses of NLP.\n",
    "\n",
    "\n",
    "We will use NLP for text analytics.\n",
    "\n",
    "\n",
    "There many libraries available for NLP in python. we will focus on the two most important one's :\n",
    "\n",
    "* Natural Languange Tool Kit (NLTK)\n",
    "* Spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we dive into text analytics using NLTK or Spacy. Let's understand about some important terminologies:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "\n",
    "Tokenization is a process of breaking down a given paragraph of text into a list of sentence or words. When paragraph is broken down into list of sentences, it is called sentence tokenization.\n",
    "Similarly, if the sentences are further broken down into list of words, it is known as Word tokenization.\n",
    "\n",
    "Let's understand this with an example. Below is a given paragraph, let's see how tokenization works on it:\n",
    "\n",
    "\"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\"\n",
    "\n",
    "* Sentence Tokenize:\n",
    "\n",
    "    ['India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia.',\n",
    "    \n",
    "  'It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world.',\n",
    "  \n",
    "  'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land      borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.',\n",
    "  \n",
    "  'In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.']\n",
    "\n",
    "\n",
    "* Word tokenize:\n",
    "\n",
    "['India', '(', 'Hindi', ':', 'Bhārat', ')', ',', 'officially', 'the', 'Republic', 'of', 'India', ',', 'is', 'a', 'country', 'in', 'South',\n",
    " 'Asia', '.', 'It', 'is', 'the', 'seventh-largest', 'country', 'by', 'area', ',', 'the', 'second-most', 'populous', 'country', ',', 'and',\n",
    " 'the', 'most', 'populous', 'democracy', 'in', 'the', 'world', '.', 'Bounded', 'by', 'the', 'Indian',\n",
    " 'Ocean',\n",
    " 'on',\n",
    " 'the',\n",
    " 'south',\n",
    " ',',\n",
    " 'the',\n",
    " 'Arabian',\n",
    " 'Sea',\n",
    " 'on',\n",
    " 'the',\n",
    " 'southwest',\n",
    " ',',\n",
    " 'and',\n",
    " 'the',\n",
    " 'Bay',\n",
    " 'of',\n",
    " 'Bengal',\n",
    " 'on',\n",
    " 'the',\n",
    " 'southeast',\n",
    " ',',\n",
    " 'it',\n",
    " 'shares',\n",
    " 'land',\n",
    " 'borders',\n",
    " 'with',\n",
    " 'Pakistan',\n",
    " 'to',\n",
    " 'the',\n",
    " 'west',\n",
    " ';',\n",
    " 'China',\n",
    " ',',\n",
    " 'Nepal',\n",
    " ',',\n",
    " 'and',\n",
    " 'Bhutan',\n",
    " 'to',\n",
    " 'the',\n",
    " 'north',\n",
    " ';',\n",
    " 'and',\n",
    " 'Bangladesh',\n",
    " 'and',\n",
    " 'Myanmar',\n",
    " 'to',\n",
    " 'the',\n",
    " 'east',\n",
    " '.',\n",
    " 'In',\n",
    " 'the',\n",
    " 'Indian',\n",
    " 'Ocean',\n",
    " ',',\n",
    " 'India',\n",
    " 'is',\n",
    " 'in',\n",
    " 'the',\n",
    " 'vicinity',\n",
    " 'of',\n",
    " 'Sri',\n",
    " 'Lanka',\n",
    " 'and',\n",
    " 'the',\n",
    " 'Maldives',\n",
    " ';',\n",
    " 'its',\n",
    " 'Andaman',\n",
    " 'and',\n",
    " 'Nicobar',\n",
    " 'Islands',\n",
    " 'share',\n",
    " 'a',\n",
    " 'maritime',\n",
    " 'border',\n",
    " 'with',\n",
    " 'Thailand',\n",
    " 'and',\n",
    " 'Indonesia',\n",
    " '.']\n",
    "\n",
    "\n",
    "Hope this example clears up the concept of tokenization. We will understand why it is done when we will dive into text analysis.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /root/anaconda3/lib/python3.8/site-packages (3.5)\n",
      "Requirement already satisfied: joblib in /root/anaconda3/lib/python3.8/site-packages (from nltk) (0.17.0)\n",
      "Requirement already satisfied: regex in /root/anaconda3/lib/python3.8/site-packages (from nltk) (2020.10.15)\n",
      "Requirement already satisfied: click in /root/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /root/anaconda3/lib/python3.8/site-packages (from nltk) (4.50.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia.',\n",
       " 'It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world.',\n",
       " 'Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east.',\n",
       " 'In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizing using NLTK\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "\n",
    "data = \"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\"\n",
    "\n",
    "nltk.sent_tokenize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India',\n",
       " '(',\n",
       " 'Hindi',\n",
       " ':',\n",
       " 'Bhārat',\n",
       " ')',\n",
       " ',',\n",
       " 'officially',\n",
       " 'the',\n",
       " 'Republic',\n",
       " 'of',\n",
       " 'India',\n",
       " ',',\n",
       " 'is',\n",
       " 'a',\n",
       " 'country',\n",
       " 'in',\n",
       " 'South',\n",
       " 'Asia',\n",
       " '.',\n",
       " 'It',\n",
       " 'is',\n",
       " 'the',\n",
       " 'seventh-largest',\n",
       " 'country',\n",
       " 'by',\n",
       " 'area',\n",
       " ',',\n",
       " 'the',\n",
       " 'second-most',\n",
       " 'populous',\n",
       " 'country',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'most',\n",
       " 'populous',\n",
       " 'democracy',\n",
       " 'in',\n",
       " 'the',\n",
       " 'world',\n",
       " '.',\n",
       " 'Bounded',\n",
       " 'by',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " 'on',\n",
       " 'the',\n",
       " 'south',\n",
       " ',',\n",
       " 'the',\n",
       " 'Arabian',\n",
       " 'Sea',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southwest',\n",
       " ',',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Bay',\n",
       " 'of',\n",
       " 'Bengal',\n",
       " 'on',\n",
       " 'the',\n",
       " 'southeast',\n",
       " ',',\n",
       " 'it',\n",
       " 'shares',\n",
       " 'land',\n",
       " 'borders',\n",
       " 'with',\n",
       " 'Pakistan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'west',\n",
       " ';',\n",
       " 'China',\n",
       " ',',\n",
       " 'Nepal',\n",
       " ',',\n",
       " 'and',\n",
       " 'Bhutan',\n",
       " 'to',\n",
       " 'the',\n",
       " 'north',\n",
       " ';',\n",
       " 'and',\n",
       " 'Bangladesh',\n",
       " 'and',\n",
       " 'Myanmar',\n",
       " 'to',\n",
       " 'the',\n",
       " 'east',\n",
       " '.',\n",
       " 'In',\n",
       " 'the',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " ',',\n",
       " 'India',\n",
       " 'is',\n",
       " 'in',\n",
       " 'the',\n",
       " 'vicinity',\n",
       " 'of',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " 'and',\n",
       " 'the',\n",
       " 'Maldives',\n",
       " ';',\n",
       " 'its',\n",
       " 'Andaman',\n",
       " 'and',\n",
       " 'Nicobar',\n",
       " 'Islands',\n",
       " 'share',\n",
       " 'a',\n",
       " 'maritime',\n",
       " 'border',\n",
       " 'with',\n",
       " 'Thailand',\n",
       " 'and',\n",
       " 'Indonesia',\n",
       " '.']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Tags and Chunking\n",
    "\n",
    "* Parts Of Speech Tagging(POS tags)\n",
    "\n",
    "As the name suggests, it is a method of tagging individual words on the basis of it's parts of speech.\n",
    "\n",
    "Wikipedia definition : Part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging or word-category disambiguation, is the process of marking up a word in a text (corpus) as corresponding to a particular part of speech,based on both its definition and its context i.e., its relationship with adjacent and related words in a phrase, sentence, or paragraph. A simplified form of this is commonly taught to school-age children, in the identification of words as nouns, verbs, adjectives, adverbs, etc.\n",
    "\n",
    "There are 9 parts of speech in grammars, but in NLP there are more than 9 POS tags based on different set of rules, such as:\n",
    "\n",
    "* NN noun, singular 'table'\n",
    "* NNS noun plural 'tables'\n",
    "* NNP proper noun, singular \n",
    "* NNPS proper noun, plural \n",
    "\n",
    "There are 4 types of division for noun only. Similarly, there are multiple divisions for other part of speeches.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('!', '.'),\n",
       " ('see', 'VB'),\n",
       " ('an', 'DT'),\n",
       " ('example', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('POS', 'NNP'),\n",
       " ('tagging', 'NN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "data =' We will! see an example of POS tagging.'\n",
    "\n",
    "pos = nltk.pos_tag(nltk.word_tokenize(data))\n",
    "\n",
    "pos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop Words\n",
    "Stop words are such words which are very common in occurrence such as ‘a’,’an’,’the’, ‘at’ etc. We ignore such words during the preprocessing part since they do not give any important information and would just take additional space. We can make our custom list of stop words as well if we want. Different libraries have different stop words list. Let’s see the stop words list for NLTK:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We also have punctuations which we can ignore from our set of words just like stopwords.\n",
    "\n",
    "import string\n",
    "\n",
    "punct =string.punctuation\n",
    "punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['India',\n",
       " 'Hindi',\n",
       " 'Bhārat',\n",
       " 'officially',\n",
       " 'Republic',\n",
       " 'India',\n",
       " 'country',\n",
       " 'South',\n",
       " 'Asia',\n",
       " 'It',\n",
       " 'seventh-largest',\n",
       " 'country',\n",
       " 'area',\n",
       " 'second-most',\n",
       " 'populous',\n",
       " 'country',\n",
       " 'populous',\n",
       " 'democracy',\n",
       " 'world',\n",
       " 'Bounded',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " 'south',\n",
       " 'Arabian',\n",
       " 'Sea',\n",
       " 'southwest',\n",
       " 'Bay',\n",
       " 'Bengal',\n",
       " 'southeast',\n",
       " 'shares',\n",
       " 'land',\n",
       " 'borders',\n",
       " 'Pakistan',\n",
       " 'west',\n",
       " 'China',\n",
       " 'Nepal',\n",
       " 'Bhutan',\n",
       " 'north',\n",
       " 'Bangladesh',\n",
       " 'Myanmar',\n",
       " 'east',\n",
       " 'In',\n",
       " 'Indian',\n",
       " 'Ocean',\n",
       " 'India',\n",
       " 'vicinity',\n",
       " 'Sri',\n",
       " 'Lanka',\n",
       " 'Maldives',\n",
       " 'Andaman',\n",
       " 'Nicobar',\n",
       " 'Islands',\n",
       " 'share',\n",
       " 'maritime',\n",
       " 'border',\n",
       " 'Thailand',\n",
       " 'Indonesia']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's word tokenize the given sample after we remove the stopwords and punctuation. \n",
    "\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "punct =string.punctuation\n",
    "\n",
    "data = \"India (Hindi: Bhārat), officially the Republic of India, is a country in South Asia. It is the seventh-largest country by area, the second-most populous country, and the most populous democracy in the world. Bounded by the Indian Ocean on the south, the Arabian Sea on the southwest, and the Bay of Bengal on the southeast, it shares land borders with Pakistan to the west; China, Nepal, and Bhutan to the north; and Bangladesh and Myanmar to the east. In the Indian Ocean, India is in the vicinity of Sri Lanka and the Maldives; its Andaman and Nicobar Islands share a maritime border with Thailand and Indonesia.\"\n",
    "clean_data =[]\n",
    "for word in nltk.word_tokenize(data):\n",
    "    if word not in punct:\n",
    "        if word not in stop_words:\n",
    "            clean_data.append(word)\n",
    "            \n",
    "clean_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Great!! Our data looks so much cleaner now after removing stop words and punctuation.**\n",
    "\n",
    "Hope, this clears up why we should remove stop words and punctuation before processing our data.\n",
    "\n",
    "Let's see pos tagging for our cleaned data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('India', 'NNP'),\n",
       " ('Hindi', 'NNP'),\n",
       " ('Bhārat', 'NNP'),\n",
       " ('officially', 'RB'),\n",
       " ('Republic', 'NNP'),\n",
       " ('India', 'NNP'),\n",
       " ('country', 'NN'),\n",
       " ('South', 'NNP'),\n",
       " ('Asia', 'IN'),\n",
       " ('It', 'PRP'),\n",
       " ('seventh-largest', 'JJ'),\n",
       " ('country', 'NN'),\n",
       " ('area', 'NN'),\n",
       " ('second-most', 'RB'),\n",
       " ('populous', 'JJ'),\n",
       " ('country', 'NN'),\n",
       " ('populous', 'JJ'),\n",
       " ('democracy', 'NN'),\n",
       " ('world', 'NN'),\n",
       " ('Bounded', 'NNP'),\n",
       " ('Indian', 'JJ'),\n",
       " ('Ocean', 'NNP'),\n",
       " ('south', 'NN'),\n",
       " ('Arabian', 'NNP'),\n",
       " ('Sea', 'NNP'),\n",
       " ('southwest', 'JJS'),\n",
       " ('Bay', 'NNP'),\n",
       " ('Bengal', 'NNP'),\n",
       " ('southeast', 'NN'),\n",
       " ('shares', 'NNS'),\n",
       " ('land', 'VBP'),\n",
       " ('borders', 'NNS'),\n",
       " ('Pakistan', 'NNP'),\n",
       " ('west', 'JJS'),\n",
       " ('China', 'NNP'),\n",
       " ('Nepal', 'NNP'),\n",
       " ('Bhutan', 'NNP'),\n",
       " ('north', 'JJ'),\n",
       " ('Bangladesh', 'NNP'),\n",
       " ('Myanmar', 'NNP'),\n",
       " ('east', 'NN'),\n",
       " ('In', 'IN'),\n",
       " ('Indian', 'JJ'),\n",
       " ('Ocean', 'NNP'),\n",
       " ('India', 'NNP'),\n",
       " ('vicinity', 'NN'),\n",
       " ('Sri', 'NNP'),\n",
       " ('Lanka', 'NNP'),\n",
       " ('Maldives', 'NNP'),\n",
       " ('Andaman', 'NNP'),\n",
       " ('Nicobar', 'NNP'),\n",
       " ('Islands', 'NNP'),\n",
       " ('share', 'NN'),\n",
       " ('maritime', 'JJ'),\n",
       " ('border', 'NN'),\n",
       " ('Thailand', 'NNP'),\n",
       " ('Indonesia', 'NNP')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(clean_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming and Lemmatization\n",
    "\n",
    "Many words that are used in a sentence are not always used in their basic form but are used as per the rules of grammar e.g.\n",
    "\n",
    "running ---> run (base word)\n",
    "\n",
    "runs    ---> run (base word)    \n",
    "\n",
    "ran     ---> run (base word)\n",
    "\n",
    "Although, the underlying meaning will be same but form of the base word changes to preserve the correct grammatical meaning.\n",
    "\n",
    "Stemming and Lemmatization are basically used to bring such words to their basic forms, so that the words with same base are treated as same words rather than treated differently.\n",
    "\n",
    "The only difference in Stemming and Lemmatization is the way in which they change the word to its base form.\n",
    "\n",
    "* Stemming\n",
    "\n",
    "Stemming means mapping a group of words to the same stem by removing prefixes or suffixes without giving any value to the “grammatical meaning” of the stem formed after the process.\n",
    "\n",
    "e.g.\n",
    "\n",
    "computation --> comput\n",
    "\n",
    "computer --> comput \n",
    "\n",
    "hobbies --> hobbi\n",
    "\n",
    "We can see that stemming tries to bring the word back to their base word but the base word may or may not have correct grammatical meanings.\n",
    "\n",
    "There are typically two types of stemmers available in NLTK package.\n",
    "1)\tPorter Stemmer \n",
    "2)\tLancaster Stemmer\n",
    "\n",
    "Let’s see how to use both of them: \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Porter stemmer\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n",
      "**************************\n",
      "lancaster stemmer\n",
      "hobby\n",
      "hobby\n",
      "comput\n",
      "comput\n",
      "**************************\n",
      "Snowball stemmer\n",
      "hobbi\n",
      "hobbi\n",
      "comput\n",
      "comput\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer, SnowballStemmer\n",
    "\n",
    "lancaster = LancasterStemmer()\n",
    "porter = PorterStemmer()\n",
    "Snowball = SnowballStemmer(\"english\")\n",
    "print('Porter stemmer')\n",
    "print(porter.stem(\"hobby\"))\n",
    "print(porter.stem(\"hobbies\"))\n",
    "print(porter.stem(\"computer\"))\n",
    "print(porter.stem(\"computation\"))\n",
    "print(\"**************************\")  \n",
    "print('lancaster stemmer')\n",
    "print(lancaster.stem(\"hobby\"))\n",
    "print(lancaster.stem(\"hobbies\"))\n",
    "print(lancaster.stem(\"computer\"))\n",
    "print(porter.stem(\"computation\"))\n",
    "print(\"**************************\")  \n",
    "print('Snowball stemmer')\n",
    "print(Snowball.stem(\"hobby\"))\n",
    "print(Snowball.stem(\"hobbies\"))\n",
    "print(Snowball.stem(\"computer\"))\n",
    "print(Snowball.stem(\"computation\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i was go to the offic on my bike when i saw a car pass by hit the tree .\n",
      "i was going to the off on my bik when i saw a car pass by hit the tre .\n",
      "I wa go to the offic on my bike when i saw a car pass by hit the tree .\n"
     ]
    }
   ],
   "source": [
    "sent = \"I was going to the office on my bike when i saw a car passing by hit the tree.\"\n",
    "token = list(nltk.word_tokenize(sent))\n",
    "for stemmer in (Snowball, lancaster, porter):\n",
    "    stemm = [stemmer.stem(t) for t in token]\n",
    "    print(\" \".join(stemm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lancaster algorithm is faster than porter but it is more complex.\n",
    "Porter stemmer is the oldest algorithm present and was the most popular to use.\n",
    "\n",
    "Snowball stemmer, also known as  porter2, is the updated version of the Porter stemmer and is currently the most popular stemming algorithm.\n",
    "\n",
    "Snowball stemmer is available for multiple languages as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "ran\n"
     ]
    }
   ],
   "source": [
    "print(porter.stem(\"running\"))\n",
    "print(porter.stem(\"runs\"))\n",
    "print(porter.stem(\"ran\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Lemmatization\n",
    "\n",
    "\n",
    "Lemmatization also does the same thing as stemming and try to bring a word to its base form, but unlike stemming it do keep in account the actual meaning of the base word i.e. the base word belongs to any specific language. The ‘base word’ is known as ‘Lemma’.\n",
    "\n",
    "We use WordNet Lemmatizer for Lemmatization in nltk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running\n",
      "run\n",
      "ran\n"
     ]
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "print(lemma.lemmatize('running'))\n",
    "print(lemma.lemmatize('runs'))\n",
    "print(lemma.lemmatize('ran'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we can see the lemma has changed for the words with same base. \n",
    "\n",
    "This is because, we haven’t given any context to the Lemmatizer.\n",
    "\n",
    "Generally, it is given by passing the POS tags for the words in a sentence.\n",
    "e.g.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n",
      "run\n",
      "run\n"
     ]
    }
   ],
   "source": [
    "print(lemma.lemmatize('running',pos='v'))\n",
    "print(lemma.lemmatize('runs',pos='v'))\n",
    "print(lemma.lemmatize('ran',pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lemmatizer is very complex and takes a lot of time to calculate.\n",
    "\n",
    "So, it should only when the real meaning of words or the context is necessary for processing, else stemming should be preferred.\n",
    "\n",
    "It completely depends on the type of problem you are trying to solve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition(NER)\n",
    "\n",
    "In chunking, we read that we can set rules to keep different POS tags under one sinlge user defined tag. One such form of chunking in NLP is known as Named Entity Recognition.\n",
    "\n",
    "In NER, we try to group entities like people, places, countries, things etc. together.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (GPE India/NNP)\n",
      "  ,/,\n",
      "  officially/RB\n",
      "  the/DT\n",
      "  (ORGANIZATION Republic/NNP)\n",
      "  of/IN\n",
      "  (GPE India/NNP)\n",
      "  ,/,\n",
      "  is/VBZ\n",
      "  a/DT\n",
      "  country/NN\n",
      "  in/IN\n",
      "  (GPE South/NNP Asia/NNP)\n",
      "  ./.)\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('maxent_ne_chunker')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')\n",
    "\n",
    "sent = \"India, officially the Republic of India, is a country in South Asia.\"\n",
    "\n",
    "words = nltk.word_tokenize(sent)\n",
    "pos_tag = nltk.pos_tag(words)\n",
    "namedEntity = nltk.ne_chunk(pos_tag)\n",
    "print(namedEntity)\n",
    "namedEntity.draw()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph \n",
    "\n",
    "<img src=\"NER1.PNG\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"NER2.PNG\">\n",
    "\n",
    "\n",
    "image source= nltk.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of NER, we can select any particular category from a given word document or sentence.\n",
    "Suppose we need all the names mentioned in a document, we can use NER and select the words with tag \"Person\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
